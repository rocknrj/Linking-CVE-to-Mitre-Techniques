{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e297ea0",
   "metadata": {},
   "source": [
    "# Note:\n",
    "- If possible save MLSMOTE augmentation for both augmented and fixed datasets to a file that can be called seperately. This will help improve the speed when testing other models/performance evaluqtion strategies as MLSMOTE can take time balancing the datasets and repeating it for each code can be very time consuming.\n",
    "\n",
    "- This code is still being executed at the time of writing this so I am assuming that the code is working here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74b2aa",
   "metadata": {},
   "source": [
    "## MLSMOTE Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0298fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def create_dataset(n_sample=1000):\n",
    "    ''' \n",
    "    Create an unevenly distributed sample data set multilabel  \n",
    "    classification using make_classification function\n",
    "    \n",
    "    args\n",
    "    nsample: int, Number of sample to be created\n",
    "    \n",
    "    return\n",
    "    X: pandas.DataFrame, feature vector dataframe with 10 features \n",
    "    y: pandas.DataFrame, target vector dataframe with 5 labels\n",
    "    '''\n",
    "    X, y = make_classification(n_classes=5, class_sep=2,\n",
    "                               weights=[0.1,0.025, 0.205, 0.008, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
    "                               n_features=10, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
    "    y = pd.get_dummies(y, prefix='class')\n",
    "    return pd.DataFrame(X), y\n",
    "\n",
    "def get_tail_label(df: pd.DataFrame, ql=[0.05, 1.]) -> list:\n",
    "    \"\"\"\n",
    "    Find the underrepresented targets.\n",
    "    Underrepresented targets are those which are observed less than the median occurrence.\n",
    "    Targets beyond a quantile limit are filtered.\n",
    "    \"\"\"\n",
    "    irlbl = df.sum(axis=0)\n",
    "    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n",
    "    irlbl = irlbl.max() / irlbl\n",
    "    threshold_irlbl = irlbl.median()\n",
    "    tail_label = irlbl[irlbl > threshold_irlbl].index.tolist()\n",
    "    return tail_label\n",
    "\n",
    "def get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.05, 1.]):\n",
    "    \"\"\"\n",
    "    return\n",
    "    X_sub: pandas.DataFrame, the feature vector minority dataframe\n",
    "    y_sub: pandas.DataFrame, the target vector minority dataframe\n",
    "    \"\"\"\n",
    "    tail_labels = get_tail_label(y, ql=ql)\n",
    "    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n",
    "    \n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop=True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop=True)\n",
    "    return X_sub, y_sub\n",
    "\n",
    "def nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n",
    "    \"\"\"\n",
    "    Give the index of 10 nearest neighbor of all the instances\n",
    "    \n",
    "    args\n",
    "    X: np.array, array whose nearest neighbor has to find\n",
    "    \n",
    "    return\n",
    "    indices: list of list, index of 5 NN of each element in X\n",
    "    \"\"\"\n",
    "    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n",
    "    euclidean, indices = nbs.kneighbors(X)\n",
    "    return indices\n",
    "\n",
    "def MLSMOTE(X, y, n_sample, neigh=5):\n",
    "    \"\"\"\n",
    "    Give the augmented data using MLSMOTE algorithm\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, input vector DataFrame\n",
    "    y: pandas.DataFrame, feature vector dataframe\n",
    "    n_sample: int, number of newly generated sample\n",
    "    \n",
    "    return\n",
    "    new_X: pandas.DataFrame, augmented feature vector data\n",
    "    target: pandas.DataFrame, augmented target vector data\n",
    "    \"\"\"\n",
    "    indices2 = nearest_neighbour(X, neigh=5)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_sample, X.shape[1]))\n",
    "    target = np.zeros((n_sample, y.shape[1]))\n",
    "    for i in range(n_sample):\n",
    "        reference = random.randint(0, n-1)\n",
    "        neighbor = random.choice(indices2[reference, 1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis=0, skipna=True)\n",
    "        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference, :] - X.loc[neighbor, :]\n",
    "        new_X[i] = np.array(X.loc[reference, :] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    return new_X, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c84b0c4",
   "metadata": {},
   "source": [
    "## MLSMOTE on Augmented Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974740a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    X, y, test_size=800, random_state=42)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Create an instance of MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for train_indices, test_indices in mskf.split(X_train_cv, y_train_cv):\n",
    "    X_train, X_test = X_train_cv[train_indices], X_train_cv[test_indices]\n",
    "    y_train, y_test = y_train_cv[train_indices], y_train_cv[test_indices]\n",
    "\n",
    "    # Convert NumPy arrays to Pandas DataFrames\n",
    "    X_train_df = pd.DataFrame(X_train.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "\n",
    "    # Apply MLSMOTE to augment the training data\n",
    "    X_train_augmented, y_train_augmented = MLSMOTE(X_train_df, y_train_df, n_sample=100, neigh=5)\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test, scores2)\n",
    "    accuracy_value = accuracy_score(y_test, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64565da7",
   "metadata": {},
   "source": [
    "## MLSMOTE on Fixed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    X, y, test_size=200, random_state=42)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Create an instance of MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for train_indices, test_indices in mskf.split(X_train_cv, y_train_cv):\n",
    "    X_train, X_test = X_train_cv[train_indices], X_train_cv[test_indices]\n",
    "    y_train, y_test = y_train_cv[train_indices], y_train_cv[test_indices]\n",
    "\n",
    "    # Convert NumPy arrays to Pandas DataFrames\n",
    "    X_train_df = pd.DataFrame(X_train.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    y_train_df = pd.DataFrame(y_train, columns=mlb.classes_)\n",
    "\n",
    "    # Apply MLSMOTE to augment the training data\n",
    "    X_train_augmented, y_train_augmented = MLSMOTE(X_train_df, y_train_df, n_sample=100, neigh=5)\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test, scores2)\n",
    "    accuracy_value = accuracy_score(y_test, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf0acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
