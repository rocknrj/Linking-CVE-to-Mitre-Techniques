{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4128b4b4",
   "metadata": {},
   "source": [
    "# Details\n",
    "\n",
    "- Augmented Dataset mainly used for the cross validation methods: cross_val_predict, cross_validate, StratifiedKFold and MultilabelStratifiedKFold(Iterative Stratification) as the original dataset is too small for stratification and is imbalanced which seems to cause errors in some folds with the main dataset (as it is too small). However an attempt will be made despite that. Without stratification however it is unlikely for cross_val_predict and cross_validation to work due to the imbalanced dataset (even with augmentation as previously attempted KFold cross validation failed in this respect).\n",
    "\n",
    "- Data split is made the same way as Labelpowerset(neural) model such that 7877/8077 of the original data is used for cross validation performance testing while 200 is held out. Similarly, for the augmented data, as it added up to ~32k data links, which was x4 times the original dataset size, 800 data was kept aside and the rest was used to train via cross validation.\n",
    "\n",
    "- cross_val_predict is not a good metric to use to test the overall performance of the model however both the original and augmented data is passed through it for comparison with the implemented data of Labelpowerset(neural).\n",
    "\n",
    "- cross_validate is a better metric to use however Hamming Loss and Ranking Loss cannot be measured with this, so there exists a little less information to compare it to the original paper results of Labelpowerset(neural) however they can still be compared with the implemented results.\n",
    "\n",
    "- Classifier Chain's solver newton-cg is selected for this however it should be noted that liblinear performed about 0.001 points more. newton-cg was still selected as the dataset is viewed to be non linear and complex rather than simple and linear. However this is still an assumption on my part and liblinear should also be considered or tested once again. I do believe as the dataset is enhanced further newton-cg would be a better fit for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.multiclass import OneVsRestClassifier  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b8b863",
   "metadata": {},
   "source": [
    "# Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72593d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.9783373680969965\n",
      "Micro Recall: 0.9735995103514611\n",
      "Micro F1 Score: 0.9759611931932733\n",
      "Macro Precision: 0.9461397448795406\n",
      "Macro Recall: 0.9378257554090995\n",
      "Macro F1 Score: 0.9419049780249787\n",
      "Hamming Loss: 0.00782313720695187\n",
      "Ranking Loss: 0.02132759836874751\n",
      "Accuracy: 0.9781959871645686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Split the data into training and evaluation sets, keeping 800 samples aside\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=800, random_state=42)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(y_train.shape[0])\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(y_train.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(X_train, y_train[:, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train_fold, X_test_fold = X_train[train_indices], X_train[test_indices]\n",
    "    y_train_fold, y_test_fold = y_train[train_indices], y_train[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test_fold, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test_fold, scores2)\n",
    "    accuracy_value = accuracy_score(y_test_fold, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b66cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51d3a0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m logistic_regression_classifier \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogistic_regression_params)\n\u001b[0;32m     73\u001b[0m chain \u001b[38;5;241m=\u001b[39m ClassifierChain(logistic_regression_classifier, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     77\u001b[0m scores2 \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mpredict(X_test_fold)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:813\u001b[0m, in \u001b[0;36mClassifierChain.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    Class instance.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    815\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m chain_idx, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m    816\u001b[0m ]\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:632\u001b[0m, in \u001b[0;36m_BaseChain.fit\u001b[1;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[0;32m    630\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder_[chain_idx]]\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain\u001b[39m\u001b[38;5;124m\"\u001b[39m, message):\n\u001b[1;32m--> 632\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_aug[:, : (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx)], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m chain_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    634\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Split the data into training and evaluation sets, keeping 800 samples aside\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=200, random_state=42)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(y_train.shape[0])\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(y_train.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(X_train, y_train[:, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train_fold, X_test_fold = X_train[train_indices], X_train[test_indices]\n",
    "    y_train_fold, y_test_fold = y_train[train_indices], y_train[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test_fold, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test_fold, scores2)\n",
    "    accuracy_value = accuracy_score(y_test_fold, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097de1c",
   "metadata": {},
   "source": [
    "#### Attempt 2 using iterative_train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f539b90",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     43\u001b[0m     skf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold_idx, (_, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     45\u001b[0m         folds[test_index] \u001b[38;5;241m=\u001b[39m fold_idx\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Initialize lists to store evaluation metrics\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:771\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 771\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\validation.py:845\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    844\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 845\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\validation.py:522\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    519\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Split the data into training and evaluation sets, keeping 800 samples aside\n",
    "X_train, X_eval, y_train, y_eval = iterative_train_test_split(X, y, test_size=200)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(y_train.shape[0])\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(y_train.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(X_train, y_train[:, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train_fold, X_test_fold = X_train[train_indices], X_train[test_indices]\n",
    "    y_train_fold, y_test_fold = y_train[train_indices], y_train[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test_fold, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test_fold, scores2)\n",
    "    accuracy_value = accuracy_score(y_test_fold, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761aacf4",
   "metadata": {},
   "source": [
    "# Iterative Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba7496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iterative-stratification in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (0.1.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from scikit-learn->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from scikit-learn->iterative-stratification) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e45e2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.9784073089661289\n",
      "Micro Recall: 0.9772488622829789\n",
      "Micro F1 Score: 0.9778260069688425\n",
      "Macro Precision: 0.951452934123831\n",
      "Macro Recall: 0.9459775064380187\n",
      "Macro F1 Score: 0.9486198134179336\n",
      "Hamming Loss: 0.007228690770423554\n",
      "Ranking Loss: 0.019579254103784804\n",
      "Accuracy: 0.9797831376282662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    X, y, test_size=800, random_state=42)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Create an instance of MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for train_indices, test_indices in mskf.split(X_train_cv, y_train_cv):\n",
    "    X_train, X_test = X_train_cv[train_indices], X_train_cv[test_indices]\n",
    "    y_train, y_test = y_train_cv[train_indices], y_train_cv[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test, scores2)\n",
    "    accuracy_value = accuracy_score(y_test, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da8edf",
   "metadata": {},
   "source": [
    "## Iterative Stratification MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b789b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m logistic_regression_classifier \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogistic_regression_params)\n\u001b[0;32m     66\u001b[0m chain \u001b[38;5;241m=\u001b[39m ClassifierChain(logistic_regression_classifier, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     70\u001b[0m scores2 \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:813\u001b[0m, in \u001b[0;36mClassifierChain.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    Class instance.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    815\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m chain_idx, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m    816\u001b[0m ]\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:632\u001b[0m, in \u001b[0;36m_BaseChain.fit\u001b[1;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[0;32m    630\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder_[chain_idx]]\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain\u001b[39m\u001b[38;5;124m\"\u001b[39m, message):\n\u001b[1;32m--> 632\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_aug[:, : (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx)], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m chain_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    634\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    X, y, test_size=200, random_state=42)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Create an instance of MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for train_indices, test_indices in mskf.split(X_train_cv, y_train_cv):\n",
    "    X_train, X_test = X_train_cv[train_indices], X_train_cv[test_indices]\n",
    "    y_train, y_test = y_train_cv[train_indices], y_train_cv[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test, scores2)\n",
    "    accuracy_value = accuracy_score(y_test, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c9ff9",
   "metadata": {},
   "source": [
    "#### Attempt 2 on main dataset using iterative_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4200102f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m mskf \u001b[38;5;241m=\u001b[39m MultilabelStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mn_splits, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Perform multi-label stratified cross-validation\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_indices, test_indices \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     56\u001b[0m     X_train, X_test \u001b[38;5;241m=\u001b[39m X_train_cv[train_indices], X_train_cv[test_indices]\n\u001b[0;32m     57\u001b[0m     y_train, y_test \u001b[38;5;241m=\u001b[39m y_train_cv[train_indices], y_train_cv[test_indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\iterstrat\\ml_stratifiers.py:214\u001b[0m, in \u001b[0;36mMultilabelStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(MultilabelStratifiedKFold, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\validation.py:845\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[0;32m    844\u001b[0m     _ensure_no_complex_data(array)\n\u001b[1;32m--> 845\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_sparse_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\validation.py:522\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    519\u001b[0m _check_large_sparse(spmatrix, accept_large_sparse)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA sparse matrix was passed, but dense \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is required. Use X.toarray() to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = iterative_train_test_split(\n",
    "    X, y, test_size=200)\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "hamming_loss_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Create an instance of MultilabelStratifiedKFold\n",
    "mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for train_indices, test_indices in mskf.split(X_train_cv, y_train_cv):\n",
    "    X_train, X_test = X_train_cv[train_indices], X_train_cv[test_indices]\n",
    "    y_train, y_test = y_train_cv[train_indices], y_train_cv[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    logistic_regression_params = {\n",
    "        'solver': 'newton-cg',\n",
    "        'C': 5\n",
    "    }\n",
    "    logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "    \n",
    "    chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "    chain.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    scores2 = chain.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, scores2, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, scores2, average='macro')\n",
    "    hamming_loss_value = hamming_loss(y_test, scores2)\n",
    "    ranking_loss_value = label_ranking_loss(y_test, scores2)\n",
    "    accuracy_value = accuracy_score(y_test, scores2)\n",
    "\n",
    "    # Append metrics to the respective lists\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    hamming_loss_values.append(hamming_loss_value)\n",
    "    ranking_loss_values.append(ranking_loss_value)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09379648",
   "metadata": {},
   "source": [
    "# cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e9cdffc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978799030793953\n",
      "Micro Precision: 0.9769722829636782\n",
      "Micro Recall: 0.9737885891198584\n",
      "Micro F1 Score: 0.9753778381050769\n",
      "Macro Precision: 0.9827262407784887\n",
      "Macro Recall: 0.9751615752605073\n",
      "Macro F1 Score: 0.9789058151550978\n",
      "Hamming Loss: 0.008018165660669152\n",
      "Ranking Loss: 0.02123548190357941\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Create and train your classifier (e.g., 'chain' classifier)\n",
    "logistic_regression_params = {\n",
    "    'solver': 'newton-cg',\n",
    "    'C': 5\n",
    "}\n",
    "logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "\n",
    "chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "\n",
    "# Split the data into training (7877 data points) and evaluation (200 data points)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=800, random_state=42)\n",
    "\n",
    "# Use cross_val_score to get cross-validated accuracy\n",
    "cv_scores = cross_val_score(chain, X_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Use cross_val_predict to get cross-validated predictions\n",
    "cross_val_predictions = cross_val_predict(chain, X_train, y_train, cv=10)\n",
    "\n",
    "# Calculate evaluation metrics for the cross-validated predictions\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_train, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_train, cross_val_predictions, average='macro')\n",
    "hamming_loss_value = hamming_loss(y_train, cross_val_predictions)\n",
    "ranking_loss_value = label_ranking_loss(y_train, cross_val_predictions)\n",
    "\n",
    "# Print the other evaluation metrics\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1 Score:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1 Score:\", f1_macro)\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Ranking Loss:\", ranking_loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91cb98b",
   "metadata": {},
   "source": [
    "# cross_val_predict MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765f64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py\", line 813, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py\", line 632, in fit\n",
      "    estimator.fit(X_aug[:, : (X.shape[1] + chain_idx)], y, **fit_params)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1241, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(cv_scores))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Use cross_val_predict to get cross-validated predictions\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m cross_val_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics for the cross-validated predictions\u001b[39;00m\n\u001b[0;32m     54\u001b[0m precision_micro, recall_micro, f1_micro, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(y_train, cross_val_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:986\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    985\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 986\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    994\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1068\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1068\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1069\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[0;32m   1070\u001b[0m predictions \u001b[38;5;241m=\u001b[39m func(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:813\u001b[0m, in \u001b[0;36mClassifierChain.fit\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    Class instance.\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    815\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m chain_idx, estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[0;32m    816\u001b[0m ]\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py:632\u001b[0m, in \u001b[0;36m_BaseChain.fit\u001b[1;34m(self, X, Y, **fit_params)\u001b[0m\n\u001b[0;32m    630\u001b[0m y \u001b[38;5;241m=\u001b[39m Y[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder_[chain_idx]]\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChain\u001b[39m\u001b[38;5;124m\"\u001b[39m, message):\n\u001b[1;32m--> 632\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_aug[:, : (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx)], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m chain_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    634\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m chain_idx\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1246\u001b[0m     )\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sk1learn.feature_extraction.text import CountVectorizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Create and train your classifier (e.g., 'chain' classifier)\n",
    "logistic_regression_params = {\n",
    "    'solver': 'newton-cg',\n",
    "    'C': 5\n",
    "}\n",
    "logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "\n",
    "chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "\n",
    "# Split the data into training (7877 data points) and evaluation (200 data points)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=200, random_state=42)\n",
    "\n",
    "# Use cross_val_score to get cross-validated accuracy\n",
    "cv_scores = cross_val_score(chain, X_train, y_train, cv=10, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Use cross_val_predict to get cross-validated predictions\n",
    "cross_val_predictions = cross_val_predict(chain, X_train, y_train, cv=10)\n",
    "\n",
    "# Calculate evaluation metrics for the cross-validated predictions\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_train, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_train, cross_val_predictions, average='macro')\n",
    "hamming_loss_value = hamming_loss(y_train, cross_val_predictions)\n",
    "ranking_loss_value = label_ranking_loss(y_train, cross_val_predictions)\n",
    "\n",
    "# Print the other evaluation metrics\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1 Score:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1 Score:\", f1_macro)\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Ranking Loss:\", ranking_loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1306e1",
   "metadata": {},
   "source": [
    "# cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a458e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: 0.9781114537476355\n",
      "Micro Recall: 0.9753642541356167\n",
      "Micro F1 Score: 0.9767318575882374\n",
      "Macro Precision: 0.9451394561567403\n",
      "Macro Recall: 0.9390178643850859\n",
      "Macro F1 Score: 0.9419714284880207\n",
      "Accuracy: 0.9786722179403868\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, label_ranking_loss, precision_recall_fscore_support\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Create and train your classifier (e.g., 'chain' classifier)\n",
    "logistic_regression_params = {\n",
    "    'solver': 'newton-cg',\n",
    "    'C': 5\n",
    "}\n",
    "logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "\n",
    "chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "\n",
    "# Split the data into a separate test set (200 samples) and training set (remaining data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=800, random_state=42)\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'accuracy': 'accuracy',\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(chain, X_train, y_train, cv=n_splits, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics (note the 'neg_' prefix)\n",
    "mean_precision_micro = np.mean(cv_results['test_precision_micro'])\n",
    "mean_recall_micro = np.mean(cv_results['test_recall_micro'])\n",
    "mean_f1_micro = np.mean(cv_results['test_f1_micro'])\n",
    "mean_precision_macro = np.mean(cv_results['test_precision_macro'])\n",
    "mean_recall_macro = np.mean(cv_results['test_recall_macro'])\n",
    "mean_f1_macro = np.mean(cv_results['test_f1_macro'])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)\n",
    "\n",
    "# Print accuracy\n",
    "mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "print(\"Accuracy:\", mean_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a12d5",
   "metadata": {},
   "source": [
    "# cross_validate MAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a2a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision: nan\n",
      "Micro Recall: nan\n",
      "Micro F1 Score: nan\n",
      "Macro Precision: nan\n",
      "Macro Recall: nan\n",
      "Macro F1 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py\", line 813, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\multioutput.py\", line 632, in fit\n",
      "    estimator.fit(X_aug[:, : (X.shape[1] + chain_idx)], y, **fit_params)\n",
      "  File \"C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1241, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, label_ranking_loss, precision_recall_fscore_support\n",
    "\n",
    "# Load your data and preprocess it as before\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "df['description'] = df['description'].astype(str)\n",
    "X = df['description']\n",
    "y = df['technique_id']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into a binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(y)\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# Create and train your classifier (e.g., 'chain' classifier)\n",
    "logistic_regression_params = {\n",
    "    'solver': 'newton-cg',\n",
    "    'C': 5\n",
    "}\n",
    "logistic_regression_classifier = LogisticRegression(**logistic_regression_params)\n",
    "\n",
    "chain = ClassifierChain(logistic_regression_classifier, order='random')\n",
    "\n",
    "# Split the data into a separate test set (200 samples) and training set (remaining data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, random_state=42)\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "}\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_results = cross_validate(chain, X_train, y_train, cv=n_splits, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Calculate the mean of the evaluation metrics (note the 'neg_' prefix)\n",
    "mean_precision_micro = np.mean(cv_results['test_precision_micro'])\n",
    "mean_recall_micro = np.mean(cv_results['test_recall_micro'])\n",
    "mean_f1_micro = np.mean(cv_results['test_f1_micro'])\n",
    "mean_precision_macro = np.mean(cv_results['test_precision_macro'])\n",
    "mean_recall_macro = np.mean(cv_results['test_recall_macro'])\n",
    "mean_f1_macro = np.mean(cv_results['test_f1_macro'])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1 Score:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1 Score:\", mean_f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcce0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae9f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
