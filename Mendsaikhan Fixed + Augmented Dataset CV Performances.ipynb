{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad29dfd4",
   "metadata": {},
   "source": [
    "# Iterative Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c285d793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 542.5405309200287 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.07336007538279224\n",
      "Micro Precision: 0.7729382142584001\n",
      "Micro Recall: 0.779136297929079\n",
      "Micro F1: 0.7758750181502924\n",
      "Macro Precision: 0.6853173994917141\n",
      "Macro Recall: 0.6551560199981197\n",
      "Macro F1: 0.6626593620147382\n",
      "Ranking Loss: 0.22346832043294765\n",
      "Accuracy: 0.7675518740445952\n",
      "Total Testing Time: 541.5468149185181 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import time\n",
    "\n",
    "# Record the start time for training\n",
    "start_time_training = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []  # Added for accuracy calculation\n",
    "\n",
    "# Record the start time for testing\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Perform cross-validation with MultilabelStratifiedKFold\n",
    "cv = 10  # Number of folds\n",
    "kf = MultilabelStratifiedKFold(n_splits=cv)\n",
    "for train_index, test_index in kf.split(X_train_cv, y_train_cv):\n",
    "    X_train_fold, X_test_fold = X_train_cv[train_index], X_train_cv[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_cv[train_index], y_train_cv[test_index]\n",
    "\n",
    "    # Fit the classifier on the training fold\n",
    "    classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test fold\n",
    "    fold_predictions = classifier.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test_fold, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test_fold, fold_predictions.toarray())\n",
    "    accuracy_fold = accuracy_score(y_test_fold, fold_predictions)  # Calculate accuracy\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_fold)  # Append accuracy\n",
    "\n",
    "# Record the end time for testing\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate total testing time\n",
    "total_testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Record the end time for training\n",
    "end_time_training = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time_training - start_time_training\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)  # Calculate mean accuracy\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)  # Print mean accuracy\n",
    "print(\"Total Testing Time:\", total_testing_time, \"seconds\")  # Print total testing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c4a4",
   "metadata": {},
   "source": [
    "### Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be9e699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 1903.6628518104553 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.012085207151535302\n",
      "Micro Precision: 0.9634558889236035\n",
      "Micro Recall: 0.962450287330914\n",
      "Micro F1: 0.9629433576782569\n",
      "Macro Precision: 0.9295990302860367\n",
      "Macro Recall: 0.9211128325459244\n",
      "Macro F1: 0.9248332186579831\n",
      "Ranking Loss: 0.03568305859062127\n",
      "Accuracy: 0.9630253938029247\n",
      "Total Testing Time: 1900.4878973960876 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import time\n",
    "\n",
    "# Record the start time for training\n",
    "start_time_training = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings_augmented.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    embedding_array, techniques_encoded, test_size=800, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []  # Added for accuracy calculation\n",
    "\n",
    "# Record the start time for testing\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Perform cross-validation with MultilabelStratifiedKFold\n",
    "cv = 10  # Number of folds\n",
    "kf = MultilabelStratifiedKFold(n_splits=cv)\n",
    "for train_index, test_index in kf.split(X_train_cv, y_train_cv):\n",
    "    X_train_fold, X_test_fold = X_train_cv[train_index], X_train_cv[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_cv[train_index], y_train_cv[test_index]\n",
    "\n",
    "    # Fit the classifier on the training fold\n",
    "    classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test fold\n",
    "    fold_predictions = classifier.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test_fold, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test_fold, fold_predictions.toarray())\n",
    "    accuracy_fold = accuracy_score(y_test_fold, fold_predictions)  # Calculate accuracy\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_fold)  # Append accuracy\n",
    "\n",
    "# Record the end time for testing\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate total testing time\n",
    "total_testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Record the end time for training\n",
    "end_time_training = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time_training - start_time_training\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)  # Calculate mean accuracy\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)  # Print mean accuracy\n",
    "print(\"Total Testing Time:\", total_testing_time, \"seconds\")  # Print total testing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef198bac",
   "metadata": {},
   "source": [
    "# Stratified K Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9238e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 539.6053879261017 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.07560777436785035\n",
      "Micro Precision: 0.7609200174891891\n",
      "Micro Recall: 0.7831252953399276\n",
      "Micro F1: 0.7714953647629245\n",
      "Macro Precision: 0.6577119192896392\n",
      "Macro Recall: 0.6478962335963712\n",
      "Macro F1: 0.6456599306720592\n",
      "Ranking Loss: 0.22650314266937305\n",
      "Accuracy: 0.7631148736952251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(techniques_encoded.shape[0])\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(techniques_encoded.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(embedding_array[:7877], techniques_encoded[:7877, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train, X_test = embedding_array[train_indices], embedding_array[test_indices]\n",
    "    y_train, y_test = techniques_encoded[train_indices], techniques_encoded[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    classifier = LabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    fold_predictions = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test, fold_predictions.toarray())\n",
    "    accuracy_value = accuracy_score(y_test, fold_predictions)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b3adb",
   "metadata": {},
   "source": [
    "### Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bcac4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 2189.309650659561 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.014917149684544401\n",
      "Micro Precision: 0.9547845613594397\n",
      "Micro Recall: 0.9530930263644283\n",
      "Micro F1: 0.9538970819843622\n",
      "Macro Precision: 0.90625336236459\n",
      "Macro Recall: 0.8972674672873774\n",
      "Macro F1: 0.9009276606228473\n",
      "Ranking Loss: 0.04382461096719599\n",
      "Accuracy: 0.9540786980312547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings_augmented.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(techniques_encoded.shape[0])\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(techniques_encoded.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(embedding_array[:31509], techniques_encoded[:31509, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train, X_test = embedding_array[train_indices], embedding_array[test_indices]\n",
    "    y_train, y_test = techniques_encoded[train_indices], techniques_encoded[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    classifier = LabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    fold_predictions = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test, fold_predictions.toarray())\n",
    "    accuracy_value = accuracy_score(y_test, fold_predictions)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70661087",
   "metadata": {},
   "source": [
    "# cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed7cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 584.2602741718292 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (Cross-Validation) Time: 540.4271159172058 seconds\n",
      "Cross-Validation Scores:\n",
      "[0.76485149 0.73514851 0.72772277 0.71658416 0.76732673 0.70420792\n",
      " 0.73019802 0.72738538 0.7149938  0.69888476]\n",
      "Mean Accuracy: 0.7287303544480841\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.08575866377030175\n",
      "Micro Precision: 0.7335165582736946\n",
      "Micro Recall: 0.7444044019165182\n",
      "Micro F1: 0.7389203747233092\n",
      "Macro Precision: 0.6297814240435244\n",
      "Macro Recall: 0.5980546246013538\n",
      "Macro F1: 0.6062429353474856\n",
      "Ranking Loss: 0.26124603754896847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_val_predictions = cross_val_predict(classifier, embedding_array, techniques_encoded, cv=10)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Record the start time for testing (in this case, cross-validation)\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Calculate evaluation metrics during cross-validation\n",
    "hamming_loss_value = hamming_loss(techniques_encoded, cross_val_predictions)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='macro')\n",
    "ranking_loss = label_ranking_loss(techniques_encoded, cross_val_predictions.toarray())\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(classifier, embedding_array, techniques_encoded, cv=10, scoring='accuracy')\n",
    "\n",
    "# Record the end time for testing (cross-validation)\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate testing time (cross-validation)\n",
    "testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Print the testing (cross-validation) time\n",
    "print(\"Testing (Cross-Validation) Time:\", testing_time, \"seconds\")\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8add752",
   "metadata": {},
   "source": [
    "### Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9afdb9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 3059.275097846985 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (Cross-Validation) Time: 2053.092003583908 seconds\n",
      "Cross-Validation Scores:\n",
      "[0.75085113 0.73042402 0.70256886 0.72578149 0.75085113 0.70071185\n",
      " 0.73073352 0.71959146 0.69287926 0.65417957]\n",
      "Mean Accuracy: 0.7158572286853461\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.08880603734509888\n",
      "Micro Precision: 0.7254690112384905\n",
      "Micro Recall: 0.732443422669594\n",
      "Micro F1: 0.7289395347399122\n",
      "Macro Precision: 0.6194707089629496\n",
      "Macro Recall: 0.5903603559950904\n",
      "Macro F1: 0.6008123684119959\n",
      "Ranking Loss: 0.26672860101242524\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings_augmented.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=800, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_val_predictions = cross_val_predict(classifier, embedding_array, techniques_encoded, cv=10)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Record the start time for testing (in this case, cross-validation)\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Calculate evaluation metrics during cross-validation\n",
    "hamming_loss_value = hamming_loss(techniques_encoded, cross_val_predictions)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='macro')\n",
    "ranking_loss = label_ranking_loss(techniques_encoded, cross_val_predictions.toarray())\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(classifier, embedding_array, techniques_encoded, cv=10, scoring='accuracy')\n",
    "\n",
    "# Record the end time for testing (cross-validation)\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate testing time (cross-validation)\n",
    "testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Print the testing (cross-validation) time\n",
    "print(\"Testing (Cross-Validation) Time:\", testing_time, \"seconds\")\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694aa603",
   "metadata": {},
   "source": [
    "# cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b490af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 542.7246444225311 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Micro Precision: 0.7390388446799097\n",
      "Micro Recall: 0.7291220454176809\n",
      "Micro F1: 0.7338435814387181\n",
      "Macro Precision: 0.61443544832025\n",
      "Macro Recall: 0.5812485324479807\n",
      "Macro F1: 0.5902668331628411\n",
      "Accuracy: 0.7325676015556946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import label_ranking_loss, hamming_loss\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600, 650), max_iter=1000))\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training data and calculate evaluation metrics\n",
    "cv_results = cross_validate(classifier, embedding_array, techniques_encoded, cv=10, scoring=scoring)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Extract and print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Micro Precision:\", np.mean(cv_results['test_precision_micro']))\n",
    "print(\"Micro Recall:\", np.mean(cv_results['test_recall_micro']))\n",
    "print(\"Micro F1:\", np.mean(cv_results['test_f1_micro']))\n",
    "print(\"Macro Precision:\", np.mean(cv_results['test_precision_macro']))\n",
    "print(\"Macro Recall:\", np.mean(cv_results['test_recall_macro']))\n",
    "print(\"Macro F1:\", np.mean(cv_results['test_f1_macro']))\n",
    "print(\"Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b47175",
   "metadata": {},
   "source": [
    "#### The Hamming and Ranking Loss here is not calculated from cross validation below and therefore cannot be used to compare with the other models/cross validated Hamming and Ranking scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00ea5b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.06809090909090909\n",
      "Ranking Loss: 0.21502075471698112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, label_ranking_loss\n",
    "\n",
    "# Calculate Hamming loss separately\n",
    "hamming_loss_value = hamming_loss(y_eval, classifier.predict(X_eval).toarray())\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "\n",
    "# Calculate ranking loss separately\n",
    "ranking_loss_value = label_ranking_loss(y_eval, classifier.predict(X_eval).toarray())\n",
    "print(\"Ranking Loss:\", ranking_loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd2acb",
   "metadata": {},
   "source": [
    "#### As shown below, there is no metric to calculate Hamming and Ranking loss with the cross_validate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6645de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Scoring Options: dict_keys(['explained_variance', 'r2', 'max_error', 'matthews_corrcoef', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'positive_likelihood_ratio', 'neg_negative_likelihood_ratio', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Print valid scoring options\n",
    "print(\"Valid Scoring Options:\", sklearn.metrics.SCORERS.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729fe2d",
   "metadata": {},
   "source": [
    "### Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7cb4c96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 2079.1449344158173 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Micro Precision: 0.7272234121850033\n",
      "Micro Recall: 0.7250433143810173\n",
      "Micro F1: 0.7259006290842215\n",
      "Macro Precision: 0.606022581095013\n",
      "Macro Recall: 0.5772190400522585\n",
      "Macro F1: 0.5821116201149311\n",
      "Accuracy: 0.7218935371636804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import label_ranking_loss, hamming_loss\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings_augmented.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=800, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600, 650), max_iter=1000))\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training data and calculate evaluation metrics\n",
    "cv_results = cross_validate(classifier, embedding_array, techniques_encoded, cv=10, scoring=scoring)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Extract and print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Micro Precision:\", np.mean(cv_results['test_precision_micro']))\n",
    "print(\"Micro Recall:\", np.mean(cv_results['test_recall_micro']))\n",
    "print(\"Micro F1:\", np.mean(cv_results['test_f1_micro']))\n",
    "print(\"Macro Precision:\", np.mean(cv_results['test_precision_macro']))\n",
    "print(\"Macro Recall:\", np.mean(cv_results['test_recall_macro']))\n",
    "print(\"Macro F1:\", np.mean(cv_results['test_f1_macro']))\n",
    "print(\"Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015653c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
