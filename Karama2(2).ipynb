{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca7ef440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split  \n",
    "from sklearn.multiclass import OneVsRestClassifier  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss\n",
    "\n",
    "df = pd.read_excel('Updated ENISA EXTRACTED4.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "#df['label'] = df['label'].apply(lister)\n",
    "\n",
    "df['description'] = df['description'].astype(str)  \n",
    "X = df['description']  \n",
    "y = df['technique_id']  \n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()  \n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "#Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into binary matrix  \n",
    "mlb = MultiLabelBinarizer()  \n",
    "y = mlb.fit_transform(y)  \n",
    "\n",
    "# Split data into training and testing sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200)\n",
    "\n",
    "base_lr = LogisticRegression(solver='newton-cg', random_state=0,C=5)\n",
    "chain = ClassifierChain(base_lr, order = 'random', random_state=0)\n",
    "chain.fit(X_train, y_train)\n",
    "score = chain.score(X_test, y_test)\n",
    "score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "049228be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Labels: 55\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Unique Labels:\", len(mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "24cef072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 1007' ' 1012' ' 1014' ' 1016' ' 1018' ' 1027' ' 1033' ' 1037' ' 1039'\n",
      " ' 1046' ' 1049' ' 1057' ' 1062' ' 1069' ' 1070.005' ' 1080' ' 1082'\n",
      " ' 1083' ' 1087' ' 1090' ' 1110' ' 1120' ' 1124' ' 1135' ' 1185' ' 1201'\n",
      " ' 1505.003' ' 1542.003' ' 1543.001' ' 1543.003' ' 1543.004' ' 1546.001'\n",
      " ' 1546.008' ' 1547.006' ' 1547.008' ' 1552.001' ' 1552.002' ' 1553.004'\n",
      " ' 1562.001' ' 1562.003' ' 1569.001' ' 1574.004' ' 1574.010' ' 1574.011'\n",
      " ' 1647' '1134' '1546.004' '1547.009' '1552.001' '1553.004' '1558.003'\n",
      " '1562.003' '1574.001' '1574.010' 'nan']\n"
     ]
    }
   ],
   "source": [
    "print(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ee150ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'y' contains your labels\n",
    "unique_classes = np.unique(y)\n",
    "print(\"Unique Classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "58d7127f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0\n",
      "  0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0\n",
      "  0 1 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ed994",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50ca14e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_529144/2015269304.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Perform cross-validation and store fold indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfold_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Adjust the fold index as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Extract data for the fold where cross_val_score failed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    375\u001b[0m             )\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \"Supported target types are: {}. Got {!r} instead.\".format(\n\u001b[1;32m    703\u001b[0m                     \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_target_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the number of folds\n",
    "n_splits = 10  # Adjust this to match your cross-validation setup\n",
    "\n",
    "# Initialize the StratifiedKFold splitter (or use KFold if appropriate)\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and store fold indices\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "    if fold_idx == 5:  # Adjust the fold index as needed\n",
    "        # Extract data for the fold where cross_val_score failed\n",
    "        X_fold = X[test_idx]\n",
    "        y_fold = y[test_idx]\n",
    "        \n",
    "        # Now you can inspect the data in X_fold and y_fold\n",
    "        print(\"Fold Data Shape:\", X_fold.shape)\n",
    "        print(\"Fold Labels Shape:\", y_fold.shape)\n",
    "        \n",
    "        # You can also examine individual data points or labels\n",
    "        for i in range(X_fold.shape[0]):\n",
    "            sample_data = X_fold[i]\n",
    "            sample_label = y_fold[i]\n",
    "            \n",
    "            print(f\"Sample {i}: Data={sample_data}, Label={sample_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a95269f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 928, in fit\n",
      "    super().fit(X, Y, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 726, in fit\n",
      "    estimator.fit(\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1252, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.72524752, 0.76361386, 0.77475248, 0.7759901 , 0.79950495,\n",
       "       0.75742574, 0.75866337, 0.75960347, 0.76208178,        nan])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform cross-validation\n",
    "scores = cross_val_score(chain, X, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "509ec7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Use cross_val_predict with StratifiedKFold\n",
    "scores2 = cross_val_predict(chain, X, y, cv=kfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a43c7a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Classes in Predictions: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(scores2)\n",
    "\n",
    "print(\"Unique Classes in Predictions:\", unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4c899442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25b039b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores:\n",
      "[0.74218508 0.74651811 0.75425565 0.76756422 0.77870628 0.7644692\n",
      " 0.74032807 0.74682761 0.75727554        nan]\n",
      "Mean Accuracy: nan\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.007766722568010175\n",
      "Micro Precision: 0.9774406684041298\n",
      "Micro Recall: 0.974859505958052\n",
      "Micro F1: 0.9761483808862136\n",
      "Macro Precision: 0.9832092360261071\n",
      "Macro Recall: 0.9771373770056762\n",
      "Macro F1: 0.9801463590558737\n",
      "Ranking Loss: 0.02064389637358957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 928, in fit\n",
      "    super().fit(X, Y, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 726, in fit\n",
      "    estimator.fit(\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1252, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics during cross-validation\n",
    "#cross_val_predictions = cross_val_predict(chain, X, y, cv=8)\n",
    "hamming_loss_value = hamming_loss(y, scores2)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y, scores2, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y, scores2, average='macro')\n",
    "ranking_loss = label_ranking_loss(y, scores2)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(chain, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a2317bf5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores:\n",
      "[0.74218508 0.74651811 0.75425565 0.76756422 0.77870628 0.7644692\n",
      " 0.74032807 0.74682761 0.75727554        nan]\n",
      "Mean Accuracy: nan\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.007766722568010175\n",
      "Micro Precision: 0.9774406684041298\n",
      "Micro Recall: 0.974859505958052\n",
      "Micro F1: 0.9761483808862136\n",
      "Macro Precision: 0.9832092360261071\n",
      "Macro Recall: 0.9771373770056762\n",
      "Macro F1: 0.9801463590558737\n",
      "Ranking Loss: 0.02064389637358957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 928, in fit\n",
      "    super().fit(X, Y, **fit_params)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/multioutput.py\", line 726, in fit\n",
      "    estimator.fit(\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/saad/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1252, in fit\n",
      "    raise ValueError(\n",
      "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer  \n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split  \n",
    "from sklearn.multiclass import OneVsRestClassifier  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss\n",
    "\n",
    "df = pd.read_excel('augmented_data2.xlsx')\n",
    "\n",
    "def lister(x):\n",
    "    return [x]\n",
    "\n",
    "df['technique_id'] = df['technique_id'].astype(str).tolist()\n",
    "#df['label'] = df['label'].apply(lister)\n",
    "\n",
    "df['description'] = df['description'].astype(str)  \n",
    "X = df['description']  \n",
    "y = df['technique_id']  \n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()  \n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "#Split techniques into separate labels\n",
    "y = [technique.split(',') for technique in y]\n",
    "\n",
    "# Convert label column into binary matrix  \n",
    "mlb = MultiLabelBinarizer()  \n",
    "y = mlb.fit_transform(y)  \n",
    "\n",
    "# Split data into training and testing sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200)\n",
    "\n",
    "base_lr = LogisticRegression(solver='newton-cg', random_state=0,C=5)\n",
    "chain = ClassifierChain(base_lr, order = 'random', random_state=0)\n",
    "chain.fit(X_train, y_train)\n",
    "score = chain.score(X_test, y_test)\n",
    "score\n",
    "\n",
    "# Perform cross-validation\n",
    "# Use cross_val_predict with StratifiedKFold\n",
    "scores2 = cross_val_predict(chain, X, y, cv=kfold)\n",
    "\n",
    "# Calculate evaluation metrics during cross-validation\n",
    "#cross_val_predictions = cross_val_predict(chain, X, y, cv=8)\n",
    "hamming_loss_value = hamming_loss(y, scores2)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y, scores2, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y, scores2, average='macro')\n",
    "ranking_loss = label_ranking_loss(y, scores2)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(chain, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8375509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
