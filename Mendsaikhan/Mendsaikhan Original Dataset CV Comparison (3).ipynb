{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03466a7a",
   "metadata": {},
   "source": [
    "# Labelpowerset(neural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f349851",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9984a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('Updated ENISA EXTRACTED2.xlsx')\n",
    "\n",
    "# Extract the desired column from the DataFrame\n",
    "descriptions = data['description'].tolist()\n",
    "\n",
    "# Load the USE model\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "use_model = hub.load(module_url)\n",
    "\n",
    "# Generate sentence embeddings\n",
    "embeddings = use_model(descriptions)\n",
    "\n",
    "# Convert embeddings to a numpy array\n",
    "embedding_array = np.array([embedding.numpy() for embedding in embeddings])\n",
    "\n",
    "# Save the embeddings to a file\n",
    "np.save('embeddings.npy', embedding_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30380fcd",
   "metadata": {},
   "source": [
    "### cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b52786e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 78.4899730682373 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (Cross-Validation) Time: 72.34297347068787 seconds\n",
      "Cross-Validation Scores:\n",
      "[0.74628713 0.70915842 0.70420792 0.74876238 0.75247525 0.69678218\n",
      " 0.71782178 0.71747212 0.65303594 0.66914498]\n",
      "Mean Accuracy: 0.7115148085440515\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.09457654288004275\n",
      "Micro Precision: 0.7087546176166069\n",
      "Micro Recall: 0.7276162981431664\n",
      "Micro F1: 0.7180616169595566\n",
      "Macro Precision: 0.6004158439260799\n",
      "Macro Recall: 0.5842861861162042\n",
      "Macro F1: 0.5886062315788042\n",
      "Ranking Loss: 0.2793844813654149\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(100,150), max_iter=1000))\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_val_predictions = cross_val_predict(classifier, embedding_array, techniques_encoded, cv=10)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Record the start time for testing (in this case, cross-validation)\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Calculate evaluation metrics during cross-validation\n",
    "hamming_loss_value = hamming_loss(techniques_encoded, cross_val_predictions)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='macro')\n",
    "ranking_loss = label_ranking_loss(techniques_encoded, cross_val_predictions.toarray())\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(classifier, embedding_array, techniques_encoded, cv=10, scoring='accuracy')\n",
    "\n",
    "# Record the end time for testing (cross-validation)\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate testing time (cross-validation)\n",
    "testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Print the testing (cross-validation) time\n",
    "print(\"Testing (Cross-Validation) Time:\", testing_time, \"seconds\")\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e1bd4",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3578aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 522.8607506752014 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing (Cross-Validation) Time: 591.4934279918671 seconds\n",
      "Cross-Validation Scores:\n",
      "[0.75618812 0.72648515 0.70915842 0.75123762 0.75       0.69925743\n",
      " 0.73267327 0.74101611 0.66294919 0.6976456 ]\n",
      "Mean Accuracy: 0.722661090458488\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.08548205973644027\n",
      "Micro Precision: 0.7465410656461584\n",
      "Micro Recall: 0.7321304376353258\n",
      "Micro F1: 0.7392655311085935\n",
      "Macro Precision: 0.6482140010236559\n",
      "Macro Recall: 0.5939711907909438\n",
      "Macro F1: 0.6133969710358909\n",
      "Ranking Loss: 0.2586497124640607\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split\n",
    "from sklearn.metrics import hamming_loss, precision_recall_fscore_support, label_ranking_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "cross_val_predictions = cross_val_predict(classifier, embedding_array, techniques_encoded, cv=10)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Record the start time for testing (in this case, cross-validation)\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Calculate evaluation metrics during cross-validation\n",
    "hamming_loss_value = hamming_loss(techniques_encoded, cross_val_predictions)\n",
    "precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='micro')\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(techniques_encoded, cross_val_predictions, average='macro')\n",
    "ranking_loss = label_ranking_loss(techniques_encoded, cross_val_predictions.toarray())\n",
    "\n",
    "# Print the cross-validation scores\n",
    "cv_scores = cross_val_score(classifier, embedding_array, techniques_encoded, cv=10, scoring='accuracy')\n",
    "\n",
    "# Record the end time for testing (cross-validation)\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate testing time (cross-validation)\n",
    "testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Print the testing (cross-validation) time\n",
    "print(\"Testing (Cross-Validation) Time:\", testing_time, \"seconds\")\n",
    "print(\"Cross-Validation Scores:\")\n",
    "print(cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", hamming_loss_value)\n",
    "print(\"Micro Precision:\", precision_micro)\n",
    "print(\"Micro Recall:\", recall_micro)\n",
    "print(\"Micro F1:\", f1_micro)\n",
    "print(\"Macro Precision:\", precision_macro)\n",
    "print(\"Macro Recall:\", recall_macro)\n",
    "print(\"Macro F1:\", f1_macro)\n",
    "print(\"Ranking Loss:\", ranking_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b52bf",
   "metadata": {},
   "source": [
    "# MultilabelStratifiedKFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28eea488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from iterative-stratification) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from scikit-learn->iterative-stratification) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lab\\anaconda3\\envs\\mendsaikhan\\lib\\site-packages (from scikit-learn->iterative-stratification) (3.1.0)\n",
      "Installing collected packages: iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da587f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 71.76342177391052 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.0778705369322467\n",
      "Micro Precision: 0.7679461357701219\n",
      "Micro Recall: 0.7580105778910184\n",
      "Micro F1: 0.7627196847956984\n",
      "Macro Precision: 0.6778185613233769\n",
      "Macro Recall: 0.641709648252741\n",
      "Macro F1: 0.6512027096028763\n",
      "Ranking Loss: 0.23767873310878618\n",
      "Accuracy: 0.7521902553551042\n",
      "Total Testing Time: 69.65960240364075 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import time\n",
    "\n",
    "# Record the start time for training\n",
    "start_time_training = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(100, 150), max_iter=1000))\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []  # Added for accuracy calculation\n",
    "\n",
    "# Record the start time for testing\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Perform cross-validation with MultilabelStratifiedKFold\n",
    "cv = 10  # Number of folds\n",
    "kf = MultilabelStratifiedKFold(n_splits=cv)\n",
    "for train_index, test_index in kf.split(X_train_cv, y_train_cv):\n",
    "    X_train_fold, X_test_fold = X_train_cv[train_index], X_train_cv[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_cv[train_index], y_train_cv[test_index]\n",
    "\n",
    "    # Fit the classifier on the training fold\n",
    "    classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test fold\n",
    "    fold_predictions = classifier.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test_fold, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test_fold, fold_predictions.toarray())\n",
    "    accuracy_fold = accuracy_score(y_test_fold, fold_predictions)  # Calculate accuracy\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_fold)  # Append accuracy\n",
    "\n",
    "# Record the end time for testing\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate total testing time\n",
    "total_testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Record the end time for training\n",
    "end_time_training = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time_training - start_time_training\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)  # Calculate mean accuracy\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)  # Print mean accuracy\n",
    "print(\"Total Testing Time:\", total_testing_time, \"seconds\")  # Print total testing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab61fb0",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc26a1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 525.6361744403839 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.07167656909868632\n",
      "Micro Precision: 0.7902398272696113\n",
      "Micro Recall: 0.7710421644456444\n",
      "Micro F1: 0.7804616209583723\n",
      "Macro Precision: 0.7134709203097416\n",
      "Macro Recall: 0.6531418917824485\n",
      "Macro F1: 0.6737991162536703\n",
      "Ranking Loss: 0.217680362964485\n",
      "Accuracy: 0.7737712769045209\n",
      "Total Testing Time: 523.5392243862152 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import time\n",
    "\n",
    "# Record the start time for training\n",
    "start_time_training = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Set aside 200 data points for later evaluation\n",
    "X_train_cv, X_eval, y_train_cv, y_eval = train_test_split(\n",
    "    embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []  # Added for accuracy calculation\n",
    "\n",
    "# Record the start time for testing\n",
    "start_time_testing = time.time()\n",
    "\n",
    "# Perform cross-validation with MultilabelStratifiedKFold\n",
    "cv = 10  # Number of folds\n",
    "kf = MultilabelStratifiedKFold(n_splits=cv)\n",
    "for train_index, test_index in kf.split(X_train_cv, y_train_cv):\n",
    "    X_train_fold, X_test_fold = X_train_cv[train_index], X_train_cv[test_index]\n",
    "    y_train_fold, y_test_fold = y_train_cv[train_index], y_train_cv[test_index]\n",
    "\n",
    "    # Fit the classifier on the training fold\n",
    "    classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions on the test fold\n",
    "    fold_predictions = classifier.predict(X_test_fold)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test_fold, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test_fold, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test_fold, fold_predictions.toarray())\n",
    "    accuracy_fold = accuracy_score(y_test_fold, fold_predictions)  # Calculate accuracy\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_fold)  # Append accuracy\n",
    "\n",
    "# Record the end time for testing\n",
    "end_time_testing = time.time()\n",
    "\n",
    "# Calculate total testing time\n",
    "total_testing_time = end_time_testing - start_time_testing\n",
    "\n",
    "# Record the end time for training\n",
    "end_time_training = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time_training - start_time_training\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)  # Calculate mean accuracy\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)  # Print mean accuracy\n",
    "print(\"Total Testing Time:\", total_testing_time, \"seconds\")  # Print total testing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4297f6",
   "metadata": {},
   "source": [
    "# Custom Stratified Kfold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c944c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 72.28679895401001 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.08128408017018074\n",
      "Micro Precision: 0.7523798343403888\n",
      "Micro Recall: 0.7591964232568416\n",
      "Micro F1: 0.7556807179454108\n",
      "Macro Precision: 0.6584966633691695\n",
      "Macro Recall: 0.6416549167748695\n",
      "Macro F1: 0.6447675659637321\n",
      "Ranking Loss: 0.24213696431209192\n",
      "Accuracy: 0.747460239402216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Split the data into training and evaluation sets, keeping 800 samples aside\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(y_train.shape[0])\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(y_train.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(X_train, y_train[:, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train, X_test = embedding_array[train_indices], embedding_array[test_indices]\n",
    "    y_train, y_test = techniques_encoded[train_indices], techniques_encoded[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    classifier = LabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    fold_predictions = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test, fold_predictions.toarray())\n",
    "    accuracy_value = accuracy_score(y_test, fold_predictions)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b78e2f3",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c977149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 563.3751072883606 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Hamming Loss: 0.07278168958210586\n",
      "Micro Precision: 0.7839133215652166\n",
      "Micro Recall: 0.7733221772480319\n",
      "Micro F1: 0.7784387723834675\n",
      "Macro Precision: 0.6876418019145295\n",
      "Macro Recall: 0.6534923025055654\n",
      "Macro F1: 0.6610500297799663\n",
      "Ranking Loss: 0.2230208774273154\n",
      "Accuracy: 0.7682042050122273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, label_ranking_loss, hamming_loss, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Split the data into training and evaluation sets, keeping 800 samples aside\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200)\n",
    "\n",
    "# Create an empty array for storing fold indices\n",
    "folds = np.zeros(y_train.shape[0])\n",
    "\n",
    "# Define the number of splits for multi-label stratified cross-validation\n",
    "n_splits = 10\n",
    "\n",
    "# For each label, create a StratifiedKFold split and assign fold indices\n",
    "for label_idx in range(y_train.shape[1]):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for fold_idx, (_, test_index) in enumerate(skf.split(X_train, y_train[:, label_idx])):\n",
    "        folds[test_index] = fold_idx\n",
    "\n",
    "\n",
    "# Initialize variables to store evaluation metrics\n",
    "hamming_loss_values = []\n",
    "precision_micro_values = []\n",
    "recall_micro_values = []\n",
    "f1_micro_values = []\n",
    "precision_macro_values = []\n",
    "recall_macro_values = []\n",
    "f1_macro_values = []\n",
    "ranking_loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "# Perform multi-label stratified cross-validation\n",
    "for fold_idx in range(n_splits):\n",
    "    train_indices = np.where(folds != fold_idx)[0]\n",
    "    test_indices = np.where(folds == fold_idx)[0]\n",
    "\n",
    "    X_train, X_test = embedding_array[train_indices], embedding_array[test_indices]\n",
    "    y_train, y_test = techniques_encoded[train_indices], techniques_encoded[test_indices]\n",
    "\n",
    "    # Create and train your classifier (e.g., 'chain' classifier)\n",
    "    classifier = LabelPowerset(MLPClassifier(hidden_layer_sizes=(600,650), max_iter=1000))\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    fold_predictions = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    hamming_loss_fold = hamming_loss(y_test, fold_predictions)\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='micro')\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_test, fold_predictions, average='macro')\n",
    "    ranking_loss_fold = label_ranking_loss(y_test, fold_predictions.toarray())\n",
    "    accuracy_value = accuracy_score(y_test, fold_predictions)\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    hamming_loss_values.append(hamming_loss_fold)\n",
    "    precision_micro_values.append(precision_micro)\n",
    "    recall_micro_values.append(recall_micro)\n",
    "    f1_micro_values.append(f1_micro)\n",
    "    precision_macro_values.append(precision_macro)\n",
    "    recall_macro_values.append(recall_macro)\n",
    "    f1_macro_values.append(f1_macro)\n",
    "    ranking_loss_values.append(ranking_loss_fold)\n",
    "    accuracy_values.append(accuracy_value)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate mean evaluation metrics across folds\n",
    "mean_hamming_loss = np.mean(hamming_loss_values)\n",
    "mean_precision_micro = np.mean(precision_micro_values)\n",
    "mean_recall_micro = np.mean(recall_micro_values)\n",
    "mean_f1_micro = np.mean(f1_micro_values)\n",
    "mean_precision_macro = np.mean(precision_macro_values)\n",
    "mean_recall_macro = np.mean(recall_macro_values)\n",
    "mean_f1_macro = np.mean(f1_macro_values)\n",
    "mean_ranking_loss = np.mean(ranking_loss_values)\n",
    "mean_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Hamming Loss:\", mean_hamming_loss)\n",
    "print(\"Micro Precision:\", mean_precision_micro)\n",
    "print(\"Micro Recall:\", mean_recall_micro)\n",
    "print(\"Micro F1:\", mean_f1_micro)\n",
    "print(\"Macro Precision:\", mean_precision_macro)\n",
    "print(\"Macro Recall:\", mean_recall_macro)\n",
    "print(\"Macro F1:\", mean_f1_macro)\n",
    "print(\"Ranking Loss:\", mean_ranking_loss)\n",
    "print(\"Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660ddd7",
   "metadata": {},
   "source": [
    "# cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69aa8a15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 95.75290417671204 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Micro Precision: 0.7248981758279057\n",
      "Micro Recall: 0.7240995083012971\n",
      "Micro F1: 0.7239856408550965\n",
      "Macro Precision: 0.6037916859530498\n",
      "Macro Recall: 0.5815998951379231\n",
      "Macro F1: 0.5830638410099673\n",
      "Accuracy: 0.7156017274589912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import label_ranking_loss, hamming_loss\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(100,150), max_iter=1000))\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training data and calculate evaluation metrics\n",
    "cv_results = cross_validate(classifier, embedding_array, techniques_encoded, cv=10, scoring=scoring)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Extract and print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Micro Precision:\", np.mean(cv_results['test_precision_micro']))\n",
    "print(\"Micro Recall:\", np.mean(cv_results['test_recall_micro']))\n",
    "print(\"Micro F1:\", np.mean(cv_results['test_f1_micro']))\n",
    "print(\"Macro Precision:\", np.mean(cv_results['test_precision_macro']))\n",
    "print(\"Macro Recall:\", np.mean(cv_results['test_recall_macro']))\n",
    "print(\"Macro F1:\", np.mean(cv_results['test_f1_macro']))\n",
    "print(\"Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98c45c",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704c89d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 536.707676410675 seconds\n",
      "Cross-Validation Evaluation Metrics:\n",
      "Micro Precision: 0.738295722371362\n",
      "Micro Recall: 0.7358785123155067\n",
      "Micro F1: 0.7367185319788504\n",
      "Macro Precision: 0.6168688002000735\n",
      "Macro Recall: 0.5995266146040219\n",
      "Macro F1: 0.6003322994318875\n",
      "Accuracy: 0.7335592341762057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lab\\anaconda3\\envs\\Mendsaikhan\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import label_ranking_loss, hamming_loss\n",
    "import time\n",
    "\n",
    "# Record the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the Excel data into a pandas DataFrame\n",
    "data = pd.read_excel('ENISA EXTRACTED.xlsx')\n",
    "\n",
    "# Extract the desired columns from the DataFrame\n",
    "cve_ids = data['cve_id'].tolist()\n",
    "techniques_str = data['technique_id'].astype(str).tolist()\n",
    "\n",
    "# Load the saved embeddings from file\n",
    "embedding_array = np.load('embeddings.npy')\n",
    "\n",
    "# Split techniques into separate labels\n",
    "techniques = [technique.split(',') for technique in techniques_str]\n",
    "\n",
    "# Create the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the techniques using the multi-label binarizer\n",
    "techniques_encoded = mlb.fit_transform(techniques)\n",
    "\n",
    "# Separate the evaluation set\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(embedding_array, techniques_encoded, test_size=200, random_state=42)\n",
    "\n",
    "# Create a custom classifier that wraps LabelPowerset\n",
    "class CustomLabelPowerset(LabelPowerset):\n",
    "    def fit(self, X, y):\n",
    "        super().fit(X, y)\n",
    "        self.classes_ = np.unique(y)\n",
    "\n",
    "# Create the Label Powerset classifier with MLP as the base classifier\n",
    "classifier = CustomLabelPowerset(MLPClassifier(hidden_layer_sizes=(600, 650), max_iter=1000))\n",
    "\n",
    "# Define the scoring metrics you want to use\n",
    "scoring = {\n",
    "    'precision_micro': 'precision_micro',\n",
    "    'recall_micro': 'recall_micro',\n",
    "    'f1_micro': 'f1_micro',\n",
    "    'precision_macro': 'precision_macro',\n",
    "    'recall_macro': 'recall_macro',\n",
    "    'f1_macro': 'f1_macro',\n",
    "    'accuracy': 'accuracy'\n",
    "}\n",
    "\n",
    "# Perform cross-validation on the training data and calculate evaluation metrics\n",
    "cv_results = cross_validate(classifier, embedding_array, techniques_encoded, cv=10, scoring=scoring)\n",
    "\n",
    "# Record the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Extract and print the evaluation metrics during cross-validation\n",
    "print(\"Cross-Validation Evaluation Metrics:\")\n",
    "print(\"Micro Precision:\", np.mean(cv_results['test_precision_micro']))\n",
    "print(\"Micro Recall:\", np.mean(cv_results['test_recall_micro']))\n",
    "print(\"Micro F1:\", np.mean(cv_results['test_f1_micro']))\n",
    "print(\"Macro Precision:\", np.mean(cv_results['test_precision_macro']))\n",
    "print(\"Macro Recall:\", np.mean(cv_results['test_recall_macro']))\n",
    "print(\"Macro F1:\", np.mean(cv_results['test_f1_macro']))\n",
    "print(\"Accuracy:\", np.mean(cv_results['test_accuracy']))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ae168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
